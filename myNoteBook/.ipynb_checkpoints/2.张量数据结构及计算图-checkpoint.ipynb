{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity='all'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一．张量数据结构\n",
    "分为常量constant和变量Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.常量张量\n",
    "在计算图中不可以被重新赋值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=1>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=1>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.23>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=3.14>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'helloworld'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=bool, numpy=True>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(1)\n",
    "tf.constant(1,dtype=tf.int64)\n",
    "tf.constant(1.23)\n",
    "tf.constant(3.14,dtype=tf.float64)\n",
    "tf.constant('helloworld')\n",
    "tf.constant(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.int64 == np.int64\n",
    "tf.bool == np.bool\n",
    "tf.double == np.float64\n",
    "tf.string == np.unicode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "记：几层中括号，即为多少维的张量\n",
    "tf.rank(v)和numpy的ndim方法相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 标量\n",
    "scalar = tf.constant(True)\n",
    "tf.rank(scalar)\n",
    "scalar.numpy().ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=1>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 向量\n",
    "vector = tf.constant([1.0,2.0,3.0])\n",
    "tf.rank(vector)\n",
    "vector.numpy().ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 矩阵\n",
    "matrix = tf.constant([[1,2],[3,4]])\n",
    "tf.rank(matrix).numpy()\n",
    "np.ndim(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy=\n",
       "array([[[1, 2],\n",
       "        [3, 4]],\n",
       "\n",
       "       [[1, 2],\n",
       "        [3, 4]]], dtype=int32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=3>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ３维\n",
    "t3 = tf.constant([[[1,2],[3,4]],[[1,2],[3,4]]])\n",
    "t3\n",
    "tf.rank(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 2, 2), dtype=int32, numpy=\n",
       "array([[[[1, 2],\n",
       "         [3, 4]],\n",
       "\n",
       "        [[1, 2],\n",
       "         [3, 4]]],\n",
       "\n",
       "\n",
       "       [[[5, 6],\n",
       "         [7, 8]],\n",
       "\n",
       "        [[5, 6],\n",
       "         [7, 8]]]], dtype=int32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t4 = tf.constant([[[[1,2],[3,4]],[[1,2],[3,4]]],[[[5,6],[7,8]],[[5,6],[7,8]]]])\n",
    "t4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以通过tf.cast改变张量的数据类型\n",
    "\n",
    "可以用numpy()将tensorflow的张量转换为numpy中的张量\n",
    "\n",
    "可以用shape()方法查看张量的尺寸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'int32'> <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "h = tf.constant([11,12],dtype=tf.int32)\n",
    "f = tf.cast(h,tf.float32)\n",
    "print(h.dtype,f.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]], dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = tf.constant([[1,2],[3,4]])\n",
    "y.numpy()\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd\\xe3\\x80\\x80\\xe4\\xb8\\x96\\xe7\\x95\\x8c'\n",
      "你好　世界\n"
     ]
    }
   ],
   "source": [
    "u = tf.constant(u'你好　世界')\n",
    "print(u.numpy())\n",
    "print(u.numpy().decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.变量张量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型中被训练的参数一般被设置为变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 2], shape=(2,), dtype=int32)\n",
      "140581530456808\n",
      "tf.Tensor([4 6], shape=(2,), dtype=int32)\n",
      "140581530457312\n"
     ]
    }
   ],
   "source": [
    "c = tf.constant([1,2])\n",
    "print(c)\n",
    "print(id(c))\n",
    "\n",
    "c = c + tf.constant([3,4])\n",
    "print(c)\n",
    "print(id(c))\n",
    "# 常量值不可以改变，重新赋值相当于创造新的内存空间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(2,) dtype=int8, numpy=array([1, 2], dtype=int8)>\n",
      "140581531657552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2,) dtype=int8, numpy=array([4, 6], dtype=int8)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(2,) dtype=int8, numpy=array([4, 6], dtype=int8)>\n",
      "140581531657552\n"
     ]
    }
   ],
   "source": [
    "# 变量的值可以改变，可以通过assign_add等方法重新赋值\n",
    "v = tf.Variable([1,2],dtype=tf.int8)\n",
    "print(v)\n",
    "print(id(v))\n",
    "\n",
    "v.assign_add([3,4])\n",
    "print(v)\n",
    "print(id(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二．三种计算图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "存在三种计算图的构建方法：静态计算图，动态计算图，AutoGraph\n",
    "\n",
    "在TF1.0，采用的是静态计算图，需要首先完成各种算子的创建，然后构建计算图，最后开启一个Session,显式地执行计算图;好处：构建完成之后几乎全部是在TF内部使用C++代码运行，效率更高;此外，还会对计算步骤进行一定的优化．\n",
    "\n",
    "在TF2.0，采用的是动态计算图，每个算子在定义完毕，自动加入到隐含的默认计算图中立即执行获取到计算结果，无需开启Session.好处是方便调试程序，缺点是运行效率低．\n",
    "\n",
    "要在Tf2.0使用静态图,可以使用＠tf.function装饰器将普通的python函数转换成对应的TF计算图构建代码，相当于在TF1.0中Session执行代码，称之为AutoGraph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### １．计算图简介\n",
    "计算图由节点（nodes）和线(edges)组成．\n",
    "\n",
    "节点表示操作符Operator,线表示节点间的依赖．\n",
    "\n",
    "实线表示的是节点之间数据的传递，传递的是张量．\n",
    "\n",
    "虚线表示的是节点之间控制的依赖，即执行的先后顺序．\n",
    "\n",
    "![](./../data/strjoin_graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.静态计算图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'hello world'\n"
     ]
    }
   ],
   "source": [
    "## TF2.0兼容性1.0在tf.compact.v1子模块保留对TF1.0计算图的支持\n",
    "g = tf.compat.v1.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    x = tf.compat.v1.placeholder(name='x',shape=[],dtype=tf.string)\n",
    "    y = tf.compat.v1.placeholder(name='y',shape=[],dtype=tf.string)\n",
    "    z = tf.strings.join([x,y],name='join',separator=' ')\n",
    "\n",
    "with tf.compat.v1.Session(graph=g) as sess:\n",
    "    ## fetches 相当于函数的返回值\n",
    "    result = sess.run(fetches=z,feed_dict={x:'hello',y:'world'})\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.动态计算图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "## 每个算子都是立即执行\n",
    "x = tf.constant('hello')\n",
    "y = tf.constant('world')\n",
    "z = tf.strings.join([x,y],separator=' ')\n",
    "tf.print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n",
      "tf.Tensor(b'hello world', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "## 可以对动态计算图代码的输入和输出关系定义为函数进行封装\n",
    "def strjoin(x,y,separator=' '):\n",
    "    z = tf.strings.join([x,y],separator=separator)\n",
    "    tf.print(z)\n",
    "    return z\n",
    "result = strjoin(tf.constant('hello'),tf.constant('world'))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.AutoGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "动态计算图效率较低\n",
    "\n",
    "可以使用＠tf.function装饰器将普通python函数转换为TF1.0对应的静态图构建代码;\n",
    "\n",
    "step1: 定义函数\n",
    "\n",
    "step2: 执行计算图即调用函数\n",
    "\n",
    "也就是说，可以在动态图中调试代码，需要提升效率的时候加上注解;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n",
      "tf.Tensor(b'hello world', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "@tf.function\n",
    "def strjoin(x,y,separator=' '):\n",
    "    z = tf.strings.join([x,y],separator=separator)\n",
    "    tf.print(z)\n",
    "    return z\n",
    "resu = strjoin(tf.constant('hello'),tf.constant('world'))\n",
    "print(resu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "##开启日志\n",
    "stamp = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "logdir = './../data/autograph_1/%s' %(stamp)\n",
    "writer = tf.summary.create_file_writer(logdir=logdir)\n",
    "\n",
    "##开启AutoGraph跟踪\n",
    "tf.summary.trace_on(graph=True,profiler=True)\n",
    "\n",
    "##执行AutoGraph\n",
    "result = strjoin('hello','world')\n",
    "\n",
    "#将计算图信息写入到日志\n",
    "with writer.as_default():\n",
    "    tf.summary.trace_export(name='autograph',step=0,profiler_outdir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 启动tensorboard\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-76576e0db5b041a0\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-76576e0db5b041a0\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir ./../data/autograph_1/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.自动微分机制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF一般使用tf.GradientTape来记录正向运算过程，然后自动获取梯度值．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1利用梯度磁带求导数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(-2.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(0.,name='x',dtype=tf.float32)\n",
    "a = tf.constant(1.)\n",
    "b = tf.constant(-2.)\n",
    "c = tf.constant(1.)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    y = a * tf.pow(x,2) + b*x + c\n",
    "\n",
    "dy_dx = tape.gradient(y,x)\n",
    "print(dy_dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "## 对常量也可以求道，需要增加一个watch\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch([a,b,c])\n",
    "    y = a * tf.pow(x,2) + b*x + c\n",
    "dy_dx,dy_da,dy_db,dy_dc = tape.gradient(y,[x,a,b,c])\n",
    "print(dy_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 可以二介求导\n",
    "with tf.GradientTape() as out:\n",
    "    with tf.GradientTape() as in:\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
